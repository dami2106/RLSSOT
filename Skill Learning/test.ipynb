{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c5b6706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from single_class_svm import create_svm_model, create_svm_model_robust, predict_across_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b09655a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ = '../Data/stone_pick_random_pixels_big'\n",
    "files = os.listdir(dir_ + '/groundTruth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09164840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_skills(files):\n",
    "    unique_skills = set()\n",
    "    for file in files:\n",
    "        with open(os.path.join(dir_ + '/groundTruth', file), 'r') as f:\n",
    "            lines = f.read().splitlines()\n",
    "        unique_skills.update(lines)\n",
    "    return unique_skills\n",
    "\n",
    "def segment_edges(lst, mode=\"start\"):\n",
    "    if not lst:\n",
    "        return []\n",
    "\n",
    "    if mode not in {\"start\", \"end\"}:\n",
    "        raise ValueError(\"mode must be 'start' or 'end'\")\n",
    "\n",
    "    edges = []\n",
    "    seg_start = lst[0]\n",
    "\n",
    "    for i in range(1, len(lst) + 1):\n",
    "        if i == len(lst) or lst[i] != lst[i - 1] + 1:\n",
    "            # segment ended at lst[i-1]\n",
    "            if mode == \"start\":\n",
    "                edges.append(seg_start)\n",
    "            else:  # mode == \"end\"\n",
    "                edges.append(lst[i - 1])\n",
    "            # prepare for next segment\n",
    "            if i < len(lst):\n",
    "                seg_start = lst[i]\n",
    "\n",
    "    return edges\n",
    "\n",
    "def get_start_end_states(skill, files):\n",
    "    start_states = []\n",
    "    end_states = []\n",
    "    other_states = []  # new\n",
    "\n",
    "    for file in files:\n",
    "        with open(os.path.join(dir_ + '/groundTruth', file), 'r') as f:\n",
    "            lines = f.read().splitlines()\n",
    "\n",
    "        pca_feats = np.load(os.path.join(dir_ + '/pca_features', file + '.npy'))\n",
    "        n_frames = len(pca_feats)\n",
    "        # assert n_frames == len(lines), f\"Mismatch in {file}: {n_frames} feats vs {len(lines)} labels\"\n",
    "\n",
    "        # indices where this skill appears\n",
    "        skill_indices = [i for i, x in enumerate(lines) if x == skill]\n",
    "        if not skill_indices:\n",
    "            # if the skill never occurs, then *all* frames are \"other\"\n",
    "            other_states.extend(pca_feats.tolist())\n",
    "            continue\n",
    "\n",
    "        # starts and ends for this skill's contiguous segments\n",
    "        starts = segment_edges(skill_indices, mode=\"start\")\n",
    "        ends   = segment_edges(skill_indices, mode=\"end\")\n",
    "\n",
    "        # collect start & end feature vectors\n",
    "        for s in starts:\n",
    "            start_states.append(pca_feats[s].tolist())\n",
    "        for e in ends:\n",
    "            end_states.append(pca_feats[e].tolist())\n",
    "\n",
    "        # everything else (exclude only starts and ends)\n",
    "        excluded = set(starts) | set(ends)\n",
    "        for idx in range(n_frames):\n",
    "            if idx not in excluded:\n",
    "                other_states.append(pca_feats[idx].tolist())\n",
    "\n",
    "    return (\n",
    "        np.array(start_states),\n",
    "        np.array(end_states),\n",
    "        np.array(other_states),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b03db387",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = get_unique_skills(files)\n",
    "skill_data = {}\n",
    "for skill in skills:\n",
    "    start_states, end_states, other_states = get_start_end_states(skill, files)\n",
    "    skill_data[skill] = {\n",
    "        'start_states': start_states,\n",
    "        'end_states': end_states,\n",
    "        'other_states': other_states\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccce57b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start model for skill table\n",
      "Evaluation on test set:\n",
      "Confusion Matrix:\n",
      "[[129  21]\n",
      " [ 11  39]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9214    0.8600    0.8897       150\n",
      "           1     0.6500    0.7800    0.7091        50\n",
      "\n",
      "    accuracy                         0.8400       200\n",
      "   macro avg     0.7857    0.8200    0.7994       200\n",
      "weighted avg     0.8536    0.8400    0.8445       200\n",
      "\n",
      "ROC AUC: 0.9072\n",
      "PR AUC:  0.7368\n",
      "Chosen threshold: 0.3712\n",
      "============================================================\n",
      "Start model for skill stone_pickaxe\n",
      "Evaluation on test set:\n",
      "Confusion Matrix:\n",
      "[[116  34]\n",
      " [  3  47]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9748    0.7733    0.8625       150\n",
      "           1     0.5802    0.9400    0.7176        50\n",
      "\n",
      "    accuracy                         0.8150       200\n",
      "   macro avg     0.7775    0.8567    0.7900       200\n",
      "weighted avg     0.8762    0.8150    0.8262       200\n",
      "\n",
      "ROC AUC: 0.8477\n",
      "PR AUC:  0.5162\n",
      "Chosen threshold: 0.1348\n",
      "============================================================\n",
      "Start model for skill wood_pickaxe\n",
      "Evaluation on test set:\n",
      "Confusion Matrix:\n",
      "[[99 51]\n",
      " [ 7 43]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9340    0.6600    0.7734       150\n",
      "           1     0.4574    0.8600    0.5972        50\n",
      "\n",
      "    accuracy                         0.7100       200\n",
      "   macro avg     0.6957    0.7600    0.6853       200\n",
      "weighted avg     0.8148    0.7100    0.7294       200\n",
      "\n",
      "ROC AUC: 0.7956\n",
      "PR AUC:  0.4281\n",
      "Chosen threshold: 0.1866\n",
      "============================================================\n",
      "Start model for skill wood\n"
     ]
    }
   ],
   "source": [
    "svm_start_models = {}\n",
    "\n",
    "for skill, data in skill_data.items():\n",
    "    start_states = data['start_states']\n",
    "    end_states = data['end_states']\n",
    "    other_states = data['other_states']\n",
    "    combined_other = np.concatenate((end_states, other_states), axis=0)\n",
    "\n",
    "    print(\"Start model for skill\", skill)\n",
    "    svm_start_models[skill] = create_svm_model_robust(start_states, combined_other)\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "svm_end_models = {}\n",
    "\n",
    "for skill, data in skill_data.items():\n",
    "    start_states = data['start_states']\n",
    "    end_states = data['end_states']\n",
    "    other_states = data['other_states']\n",
    "    combined_other = np.concatenate((start_states, other_states), axis=0)\n",
    "\n",
    "    print(\"End model for skill\", skill)\n",
    "    svm_end_models[skill] = create_svm_model_robust(end_states, combined_other)\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b879dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for skill in skill_data: \n",
    "    #Test the start and end models, add up correct vs incorrect vs total \n",
    "    start_states = skill_data[skill]['start_states']\n",
    "    end_states = skill_data[skill]['end_states']\n",
    "\n",
    "    correct_start = 0 \n",
    "    correct_end = 0\n",
    "    total_start = 0\n",
    "    total_end = 0\n",
    "\n",
    "    for feat in start_states:\n",
    "        predictions = predict_across_skills(feat, svm_start_models)\n",
    "        if predictions['top_skill'] == skill:\n",
    "            correct_start += 1\n",
    "        total_start += 1\n",
    "\n",
    "    for feat in end_states:\n",
    "        predictions = predict_across_skills(feat, svm_end_models)\n",
    "        if predictions['top_skill'] == skill:\n",
    "            correct_end += 1\n",
    "        total_end += 1\n",
    "\n",
    "    print(f\"Skill: {skill}\")\n",
    "    print(f\"Start Model - Correct: {correct_start}, Total: {total_start}\")\n",
    "    print(f\"End Model - Correct: {correct_end}, Total: {total_end}\")\n",
    "    print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hisd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
